{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from kgi import apply_kgi_to_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b436357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to enable LaTeX rendering\n",
    "# change to `False` if you get an error during plotting (latex not installed)\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_init_to_he_uniform(model):\n",
    "    \"\"\" Change PyTorch's default initialization to He uniform \"\"\"\n",
    "    # PyTorch default uses 1/sqrt(m) as the bound\n",
    "    # He uniform uses sqrt(3) / sqrt(m) as the bound\n",
    "    sqrt3 = np.sqrt(3)\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            layer.weight.data *= sqrt3\n",
    "            layer.bias.data *= sqrt3\n",
    "\n",
    "\n",
    "class MLP1d(nn.Module):\n",
    "    def __init__(self, hidden_size, activation=torch.relu):\n",
    "        super(MLP1d, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        self.act = activation\n",
    "        default_init_to_he_uniform(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dec2dc",
   "metadata": {},
   "source": [
    "# Visualize initialized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c21ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_knots(y, dx, threshold=1e-11):\n",
    "    \"\"\" Find indices of knots in a curve \"\"\"\n",
    "    if len(y) < 2:\n",
    "        return []\n",
    "    # calculate the slopes between consecutive points\n",
    "    slopes = (y[1:] - y[:-1]) / dx\n",
    "    # find where the slopes change\n",
    "    slope_changes = torch.abs(torch.diff(slopes))\n",
    "    knots = torch.where(slope_changes > threshold)[0] + 1  # noqa\n",
    "    return knots.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7170a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use double for more accurate knot finding\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# set number of curves\n",
    "n_curve = 10\n",
    "\n",
    "# hidden sizes to consider\n",
    "n_hidden = [5, 20]\n",
    "\n",
    "# input\n",
    "x_in = torch.linspace(0, 1, 1000).unsqueeze(1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2 * len(n_hidden), figsize=(10 / 1.02, 3 / 1.02), dpi=200)\n",
    "plt.subplots_adjust(wspace=.15)\n",
    "for i_n, n in enumerate(n_hidden):\n",
    "    n_knots_def = 0\n",
    "    n_knots_kgi = 0\n",
    "    for i in range(n_curve):\n",
    "        # default model\n",
    "        model_def = MLP1d(n)\n",
    "        model_def.eval()\n",
    "\n",
    "        # KGI model\n",
    "        model_kgi = copy.deepcopy(model_def)\n",
    "        apply_kgi_to_model(model_kgi, knot_low=0.2, knot_high=0.8,\n",
    "                           perturb_factor=0.2, kgi_by_bias=False)\n",
    "\n",
    "        # forward\n",
    "        with torch.no_grad():\n",
    "            y_def = model_def(x_in).squeeze(1)\n",
    "            y_kgi = model_kgi(x_in).squeeze(1)\n",
    "\n",
    "        # find knots\n",
    "        knots_def = find_knots(y_def, x_in[1] - x_in[0])\n",
    "        knots_kgi = find_knots(y_kgi, x_in[1] - x_in[0])\n",
    "        n_knots_def += len(knots_def)\n",
    "        n_knots_kgi += len(knots_kgi)\n",
    "\n",
    "        # plot\n",
    "        axes[i_n + 0].plot(x_in, y_def, lw=1)\n",
    "        axes[i_n + 0].scatter(x_in[knots_def], y_def[knots_def], marker=\"|\", s=80, lw=.5)\n",
    "        axes[i_n + 2].plot(x_in, y_kgi, lw=1)\n",
    "        axes[i_n + 2].scatter(x_in[knots_kgi], y_kgi[knots_kgi], marker=\"|\", s=80, lw=.5)\n",
    "\n",
    "    # title\n",
    "    axes[i_n + 0].text(x=0.5, y=-0.1,\n",
    "                       s=\"No KGI, $H=%d$\" % (n,),\n",
    "                       fontsize=12, ha='center',\n",
    "                       transform=axes[i_n + 0].transAxes)\n",
    "    axes[i_n + 0].text(x=0.5, y=1.03,\n",
    "                       s=\"$N_\\\\mathrm{knot}=%d$\" % (round(n_knots_def / n_curve),),\n",
    "                       fontsize=12, ha='center', va='bottom',\n",
    "                       transform=axes[i_n + 0].transAxes)\n",
    "    axes[i_n + 2].text(x=0.5, y=-0.1,\n",
    "                       s=\"KGI, $H=%d$\" % (n,),\n",
    "                       fontsize=12, ha='center',\n",
    "                       transform=axes[i_n + 2].transAxes)\n",
    "    axes[i_n + 2].text(x=0.5, y=1.03,\n",
    "                       s=\"$N_\\\\mathrm{knot}=%d$\" % (round(n_knots_kgi / n_curve),),\n",
    "                       fontsize=12, ha='center', va='bottom',\n",
    "                       transform=axes[i_n + 2].transAxes)\n",
    "\n",
    "# setup\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(0, 1)\n",
    "plt.savefig(\"figs/curve_knots.pdf\", bbox_inches='tight', pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c74326",
   "metadata": {},
   "source": [
    "# Curve fitting\n",
    "\n",
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "\n",
    "def gaussian(x, mu, sigma, height):\n",
    "    \"\"\" Gaussian shape \"\"\"\n",
    "    exponent = -((x - mu) ** 2) / (2 * sigma ** 2)\n",
    "    return height * torch.exp(exponent)\n",
    "\n",
    "\n",
    "# ground truth\n",
    "x_in = torch.linspace(0, 1, 1000)\n",
    "y_true = torch.zeros_like(x_in)\n",
    "y_true += gaussian(x_in, 0.15, 0.005, 1)\n",
    "y_true -= gaussian(x_in, 0.34, 0.003, .8)\n",
    "y_true -= gaussian(x_in, 0.41, 0.003, .6)\n",
    "y_true += gaussian(x_in, 0.62, 0.004, 1.2)\n",
    "y_true += gaussian(x_in, 0.8, 0.002, 0.8)\n",
    "plt.figure(figsize=(10 / 1.6 * 0.4, 3 / 1.6), dpi=200)\n",
    "plt.plot(x_in, y_true, lw=1, c=\"k\")\n",
    "plt.xlim(0, 1)\n",
    "plt.savefig(\"figs/curve_target.pdf\", bbox_inches='tight', pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441aa8e3",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f15f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(kgi, hidden_size, seed, activation=torch.relu,\n",
    "          num_epochs=10000, log_loss_every=100, device=\"cpu\", pbar=True):\n",
    "    \"\"\" Train a model \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    model = MLP1d(hidden_size, activation)\n",
    "    if kgi:\n",
    "        if activation is torch.tanh:\n",
    "            apply_kgi_to_model(model, knot_low=[0.2, -0.6, -0.6], knot_high=[0.8, 0.6, 0.6],\n",
    "                               perturb_factor=0.2, kgi_by_bias=False)\n",
    "        else:\n",
    "            apply_kgi_to_model(model, knot_low=0.2, knot_high=0.8,\n",
    "                               perturb_factor=0.2, kgi_by_bias=False)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # training loop\n",
    "    loss_hist = []\n",
    "    x_in_ = x_in.unsqueeze(1).to(device)\n",
    "    y_true_ = y_true.unsqueeze(1).to(device)\n",
    "    for epoch in trange(num_epochs, disable=not pbar):\n",
    "        y_pred = model(x_in_)\n",
    "        loss = criterion(y_pred, y_true_)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % log_loss_every == 0:\n",
    "            loss_hist.append(loss.item())\n",
    "    return model, loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all models\n",
    "reproduce_paper = False\n",
    "if reproduce_paper:\n",
    "    \"\"\" THIS WILL TAKE A LONG TIME TO TRAIN THE 10x9x4x2 MODELS \"\"\"\n",
    "    seeds = list(range(10))\n",
    "    hidden_sizes = [25, 50, 100, 200, 400, 600, 800, 1000, 1200]\n",
    "    activations = [torch.nn.functional.relu, torch.nn.functional.leaky_relu,\n",
    "                   torch.nn.functional.gelu, torch.nn.functional.tanh]\n",
    "    epochs = 30000\n",
    "    device_ = \"cuda\"\n",
    "    out_dir = Path(\"results/curve_paper\")\n",
    "    show_pbar = False\n",
    "else:\n",
    "    seeds = [0]\n",
    "    hidden_sizes = [200]\n",
    "    activations = [torch.nn.functional.relu]\n",
    "    epochs = 10000\n",
    "    device_ = \"cpu\"\n",
    "    out_dir = Path(\"results/curve_test\")\n",
    "    show_pbar = True\n",
    "\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "for act_ in activations:\n",
    "    for seed_ in seeds:\n",
    "        for hidden_size_ in hidden_sizes:\n",
    "            for kgi_ in [False, True]:\n",
    "                act_name_ = \"gelu\" if act_ is torch.nn.functional.gelu else str(act_).split(\" \")[1]\n",
    "                name_ = f\"{act_name_}_{seed_}_{hidden_size_}_{kgi_}\"\n",
    "                if not (out_dir / name_).exists():\n",
    "                    t0 = time()\n",
    "                    _, hist_ = train(kgi_, hidden_size_, seed_, act_, device=device_,\n",
    "                                     num_epochs=epochs, pbar=show_pbar)\n",
    "                    np.savetxt(out_dir / name_, hist_)\n",
    "                    print(f\"{name_} trained in {(time() - t0) / 60:.1f} min, loss={hist_[-1]:.2e}\")\n",
    "                else:\n",
    "                    print(f\"{name_} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388db2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick comparison\n",
    "hist_def = np.loadtxt(out_dir / \"relu_0_200_False\")\n",
    "hist_kgi = np.loadtxt(out_dir / \"relu_0_200_True\")\n",
    "plt.plot(hist_def)\n",
    "plt.plot(hist_kgi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c2ece",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The following cells works only when `reproduce_paper` was set `True` for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = list(range(10))\n",
    "hidden_sizes = [25, 50, 100, 200, 400, 600, 800, 1000, 1200]\n",
    "epochs = 30000\n",
    "out_dir = Path(\"results/curve_paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "def get_metrics(act_name, kgi):\n",
    "    min_loss_mean = []\n",
    "    min_loss_std = []\n",
    "    for hidden_size in hidden_sizes[:-1]:\n",
    "        hists = []\n",
    "        for seed in seeds:\n",
    "            name = f\"{act_name}_{seed}_{hidden_size}_{kgi}\"\n",
    "            hist = np.loadtxt(out_dir / name)\n",
    "            hists.append(hist)\n",
    "        hists = np.array(hists) * 1000\n",
    "        min_loss = np.min(hists, axis=1)\n",
    "        min_loss = np.sort(min_loss)\n",
    "        min_loss_mean.append(min_loss[:-2].mean())\n",
    "        min_loss_std.append(min_loss[:-2].std())\n",
    "    return np.array(min_loss_mean), np.array(min_loss_std)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(9, 2.5), dpi=200, sharex=True)\n",
    "plt.subplots_adjust(wspace=.22)\n",
    "for i, (act, act_str) in enumerate(zip([\"relu\", \"leaky_relu\", \"gelu\", \"tanh\"],\n",
    "                                       [\"ReLU\", \"LeakyReLU\", \"GELU\", \"Tanh\"])):\n",
    "    min_mean_def, min_std_def = get_metrics(act, False)\n",
    "    min_mean_kgi, min_std_kgi = get_metrics(act, True)\n",
    "    x_fake = [-400, -200, 0, 200, 400, 600, 800, 1000]\n",
    "    axes[i].errorbar(x_fake, min_mean_def, min_std_def, fmt=\"o\",\n",
    "                     markersize=3, capsize=2, capthick=1, elinewidth=1, label=\"No KGI\")\n",
    "    axes[i].errorbar(x_fake, min_mean_kgi, min_std_def, fmt=\"s\",\n",
    "                     markersize=3, capsize=2, capthick=1, elinewidth=1, label=\"KGI\")\n",
    "    axes[i].set_xticks(x_fake, [25, 50, 100, 200, 400, 600, 800, 1000])\n",
    "    for label in axes[i].get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "    axes[i].set_xlabel(\"Hidden size, $H$\")\n",
    "    axes[i].text(.5, 1.03, f\"$\\sigma$: {act_str}\", va=\"bottom\", ha=\"center\",\n",
    "                 transform=axes[i].transAxes)\n",
    "    if i == 3:\n",
    "        pass\n",
    "        # insert a zoom-in window\n",
    "        ax_inset = axes[i].inset_axes([.4, .55, .6, .45])\n",
    "        ax_inset.errorbar(x_fake, min_mean_def, min_std_def, fmt=\"o\",\n",
    "                          markersize=3, capsize=2, capthick=1, elinewidth=1)\n",
    "        ax_inset.errorbar(x_fake, min_mean_kgi, min_std_def, fmt=\"s\",\n",
    "                          markersize=3, capsize=2, capthick=1, elinewidth=1)\n",
    "        ax_inset.set_xticks([])\n",
    "        ax_inset.set_yticks([0, 0.01], [\"0\", \"0.01\"])\n",
    "        ax_inset.set_xlim(-100, 1100)\n",
    "        ax_inset.set_ylim(0, 0.014)\n",
    "        axes[i].text(500, 0.12, \"$\\\\overbrace{%s}{}$\" % (\"\".join([\"\\\\ \"] * 21),), ha=\"center\")\n",
    "        axes[i].text(500, 0.35, \"zoom\", ha=\"center\")\n",
    "\n",
    "axes[0].set_ylabel(\"MSE ($10^{-3}$)\")\n",
    "axes[0].legend()\n",
    "axes[2].set_yticks([0, 5, 10])\n",
    "axes[3].set_yticks([0, 1])\n",
    "plt.savefig(\"figs/curve_loss_H.pdf\", bbox_inches='tight', pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convergence history\n",
    "def moving_ave(data, window_size):\n",
    "    \"\"\" Moving average to smooth the loss history a little bit \"\"\"\n",
    "    return np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n",
    "\n",
    "\n",
    "_, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(9, 3), dpi=200)\n",
    "plt.subplots_adjust(wspace=.15)\n",
    "for i, hidden_size_ in enumerate(hidden_sizes[:-1]):\n",
    "    seed_ = 2\n",
    "    hist_def = np.loadtxt(out_dir / f\"relu_{seed_}_{hidden_size_}_{False}\")\n",
    "    hist_kgi = np.loadtxt(out_dir / f\"relu_{seed_}_{hidden_size_}_{True}\")\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    ax.plot(np.arange(epochs // 100 - 2) / 10, moving_ave(hist_def, 3) * 1000, label=\"No KGI\", lw=1)\n",
    "    ax.plot(np.arange(epochs // 100 - 2) / 10, moving_ave(hist_kgi, 3) * 1000, label=\"KGI\", lw=1)\n",
    "    ax.text(.95, .92, f\"$H={hidden_size_}$\", va=\"top\", ha=\"right\", transform=ax.transAxes)\n",
    "axes[0, 0].set_ylim(-3, 30)\n",
    "for i in range(2):\n",
    "    axes[i, 0].set_ylabel(\"MSE ($10^{-3}$)\")\n",
    "    axes[i, 0].set_yticks([0, 10, 20, 30])\n",
    "for i in range(4):\n",
    "    axes[1, i].set_xlabel(\"Epoch ($10^3$)\")\n",
    "    axes[1, i].set_xticks([0, 10, 20, 30])\n",
    "axes[0, 0].legend(ncol=2, loc=[0.04, 0.04], handlelength=1, columnspacing=1)\n",
    "plt.savefig(\"figs/curve_loss_epoch.pdf\", bbox_inches='tight', pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d692e3",
   "metadata": {},
   "source": [
    "# Animate training\n",
    "\n",
    "Now we zoom into the convergence process. Make sure you have `ffmpeg` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_animate(kgi, hidden_size, seed, activation=torch.relu,\n",
    "                  num_epochs=20000, plot_every=20, device=\"cpu\", pbar=True):\n",
    "    \"\"\" Animate training \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    model = MLP1d(hidden_size, activation)\n",
    "    if kgi:\n",
    "        if activation is torch.tanh:\n",
    "            apply_kgi_to_model(model, knot_low=[0.2, -0.6, -0.6], knot_high=[0.8, 0.6, 0.6],\n",
    "                               perturb_factor=0.2, kgi_by_bias=False)\n",
    "        else:\n",
    "            apply_kgi_to_model(model, knot_low=0.2, knot_high=0.8,\n",
    "                               perturb_factor=0.2, kgi_by_bias=False)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # output\n",
    "    out = Path(\"results/curve_animation\")\n",
    "    out.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # training loop\n",
    "    x_in_ = x_in.unsqueeze(1).to(device)\n",
    "    y_true_ = y_true.unsqueeze(1).to(device)\n",
    "    for epoch in trange(num_epochs, disable=not pbar):\n",
    "        y_pred = model(x_in_)\n",
    "        loss = criterion(y_pred, y_true_)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # plot a snapshot\n",
    "        if (epoch + 1) % plot_every == 0 or epoch == 0:\n",
    "            plt.figure(dpi=200)\n",
    "            plt.plot(x_in, y_true, c='gray', lw=0.5)\n",
    "            y_pred = y_pred.squeeze(1).detach().cpu()\n",
    "            knots = find_knots(y_pred, x_in[1] - x_in[0], threshold=1e-3)\n",
    "            plt.plot(x_in, y_pred, c='b', lw=1)\n",
    "            plt.scatter(x_in[knots], y_pred[knots], marker=\"|\", s=200, lw=1, c='r')\n",
    "            plt.gca().axis(\"off\")\n",
    "            plt.text(0.6, 0.24, \"KGI\" if kgi else \"No KGI\", transform=plt.gca().transAxes, fontsize=16)\n",
    "            plt.text(0.6, 0.17, f\"Epoch = {epoch + 1}\", transform=plt.gca().transAxes, fontsize=16)\n",
    "            plt.text(0.6, 0.1, f\"Loss = {loss.item():.1e}\", transform=plt.gca().transAxes, fontsize=16)\n",
    "            plt.savefig(out / f\"{'KGI' if kgi else 'No_KGI'}_{(epoch + 1) // plot_every + 1}.png\",\n",
    "                        bbox_inches='tight', pad_inches=0.01)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to `True` to generate animations in ./figs/\n",
    "make_animations = False\n",
    "\n",
    "if make_animations:\n",
    "    train_animate(kgi=False, hidden_size=25, seed=2)\n",
    "    ffmpeg_command = (f\"ffmpeg -i results/curve_animation/No_KGI_%d.png -c:v libx264 \" +  # noqa\n",
    "                      \"-framerate 10 -vf \\'scale=trunc(iw/2)*2:trunc(ih/2)*2\\' \" +\n",
    "                      \"-pix_fmt yuv420p -y figs/No_KGI.mp4\")\n",
    "    !{ffmpeg_command}\n",
    "\n",
    "    train_animate(kgi=True, hidden_size=25, seed=2)\n",
    "    ffmpeg_command = (f\"ffmpeg -i results/curve_animation/KGI_%d.png -c:v libx264 \" +  # noqa\n",
    "                      \"-framerate 30 -vf \\'scale=trunc(iw/2)*2:trunc(ih/2)*2\\' \" +\n",
    "                      \"-pix_fmt yuv420p -y figs/KGI.mp4\")\n",
    "    !{ffmpeg_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823ad15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
